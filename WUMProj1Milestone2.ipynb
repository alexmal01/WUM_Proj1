{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do uczenia maszynowego - Projekt 1\n",
    "## Aleksander Malinowski | Damian Skowroński\n",
    "___\n",
    "### Milestone 2\n",
    "Będziemy robić modele na danych, na których wykonaliśmy preprocessing w kamieniu milowym 1. W preprocessing wykonaliśmy następujące zmiany:\n",
    "\n",
    "*   dodatnie kolumn:\n",
    "    *   _black_king_dst_ - odleglość czarnego króla od brzegu planszy\n",
    "    *   _black2white_king_dst_ - odległość króli od siebie \n",
    "    *   _black2rook_dst_ - odległość czarnego króla od białej wieży\n",
    "*   wykonanie label encoding dla zmiennych określających _file_\n",
    "*   zamienienie wartości słownych w zmiennej celu _result_ na odpowiadające im liczby i wartości \"draw\" na \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white_king_file</th>\n",
       "      <th>white_king_rank</th>\n",
       "      <th>white_rook_file</th>\n",
       "      <th>white_rook_rank</th>\n",
       "      <th>black_king_file</th>\n",
       "      <th>black_king_rank</th>\n",
       "      <th>result</th>\n",
       "      <th>black_king_dst</th>\n",
       "      <th>black2white_king_dst</th>\n",
       "      <th>black2rook_dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   white_king_file  white_king_rank  white_rook_file  white_rook_rank  \\\n",
       "0                2                2                3                3   \n",
       "1                1                1                6                3   \n",
       "2                4                4                7                5   \n",
       "3                3                1                7                3   \n",
       "4                4                1                2                5   \n",
       "\n",
       "   black_king_file  black_king_rank  result  black_king_dst  \\\n",
       "0                8                3      13               0   \n",
       "1                5                3      -1               2   \n",
       "2                8                2       6               0   \n",
       "3                2                7      13               1   \n",
       "4                8                5      13               0   \n",
       "\n",
       "   black2white_king_dst  black2rook_dst  \n",
       "0                     6               5  \n",
       "1                     4               1  \n",
       "2                     4               3  \n",
       "3                     6               5  \n",
       "4                     4               6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv(\"training_set.csv\", index_col=0).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na zbiór treningowy i walidacyjny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podchodzimy do problemu przewidzenia rezultatu w następujący sposób:\n",
    "\n",
    "1.  klasyfikacja, czy doszło do remisu \"draw\" (u nas wartość \"-1\"), czy nie (dowolna inna wartość)\n",
    "2. regresja w celu przewidzenia ilości ruchów, dla wyników, które w pierwszym kroku zostały sklasyfikowane, że gra nie skończyła się remisem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja \n",
    "Ponieważ zbiór danych teoretycznie przedstawia optymalne ruchy, a przewaga białego nad czarnym jest duża, remis zachodzi zapewne w chwili kiedy czarny bije białą wieżę. Taka sytuacja zdaży się w momentcie, gdy czarny król jest w odległości od białej wieży równej \"1\", a biały król jest w odległości od białej wieży większej niż \"1\". W tym celu tworzę nową zmienną _white2rook_dst_, której nie braliśmy pod uwagę w preprocessingu (możliwe, że przyda się też potem w regresji)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white2rookdistance(df):\n",
    "     # dystans pomiędzy białym królem i wieżą\n",
    "    return max(abs(df['white_king_file'] - df['white_rook_file']),abs(df['white_king_rank'] - df['white_rook_rank']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie ze otrzymanej nowej zmiennej _white2rook_dst_ i wcześniejszej _black2rook_dst_ mogę dowiedzieć się czy czarny zbije wieżę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2r_rt(df): #white to rook distance + rook taken\n",
    "    df['white2rook_dst'] = df.apply(lambda x: white2rookdistance(x), axis = 1)\n",
    "    df[\"rook_taken\"] = np.where(\n",
    "        (df.black2rook_dst == 1) & (df.white2rook_dst != 1),\n",
    "        0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzając korelację pomiędzy nową zmienna _rook_taken_, a result w wersji remis/nieremis otrzymujemy następujący wynik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99858054],\n",
       "       [0.99858054, 1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2r_rt(df)\n",
    "np.corrcoef(df.rook_taken,df.result.apply(lambda x: 0 if x == -1 else 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wychodzi, że korelacja jest bardzo duża."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1952,     0],\n",
       "       [    5, 17682]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df.rook_taken,df.result.apply(lambda x: 0 if x == -1 else 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, nowa dokładnie opisuję sytuacje i popełniła tylko 5 błędów. Wobec tego myślę, że nie trzeba robić modelu do sklasyfikowania, a po prostu zdać się na nią. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regresja\n",
    "Regresję wykonujemy w celu dowiedzenia się ile ruchów będzie potrzebne do zamatowania. Wykonywać ją będziemy na części obserwacji, które w poprzedniej \"klasyfikacji\" nie zwróciły remisu, czyli po prostu na tych, które mają \"0\" w nowej zmiennej _rook_taken_. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_predicted_draws(df):\n",
    "    # do regresji zostawiamy tylko te wiersze w których nie ma remisu\n",
    "    # na początku sortujemy w ten spoosb, aby remisy były na początku, żeby potem łatwiej połączyć ramkę, i nie musiec pamietac o indexach\n",
    "    df_sorted = df.sort_values(\"rook_taken\").reset_index(drop=True)\n",
    "    df_draws = df_sorted.drop(index=np.where(df_sorted.rook_taken != 0)[0])\n",
    "    df_sorted_dropped = df_sorted.drop(index=np.where(df_sorted.rook_taken == 0)[0])\n",
    "    df_sorted_dropped.value_counts('result')\n",
    "    return df_draws,df_sorted_dropped\n",
    "\n",
    "df_draws, df_sorted_dropped = drop_predicted_draws(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalej podzielimy zbiór przeznaczony dla regresji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(df_sorted_dropped.drop(columns = [\"result\"]), df_sorted_dropped.result, \n",
    "                                                    test_size = 0.3, random_state= 420, stratify=df_sorted_dropped.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I poszukamy modelu, który będzie dobrze przewidywał:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042820769243767"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "regr = svm.SVR()\n",
    "regr.fit(train_X,train_y)\n",
    "regr.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = svm.SVR(kernel=\"rbf\", C=10, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = svm.SVR(kernel=\"linear\", C=10, gamma=\"auto\")\n",
    "svr_poly = svm.SVR(kernel=\"poly\", C=10, gamma=\"auto\", degree=2, epsilon=0.1, coef0=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861754774551369"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf.fit(train_X,train_y)\n",
    "svr_rbf.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6083084061232793"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_lin.fit(train_X,train_y)\n",
    "svr_lin.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694078190101433"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_poly.fit(train_X,train_y)\n",
    "svr_poly.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepiej spisał się model z kernelem \"rbf\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Regresja liniowa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6267596907146789"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_X,train_y)\n",
    "lr.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236971549427213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "las = Lasso(alpha=0.1)\n",
    "las.fit(train_X,train_y)\n",
    "las.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6267532936351177"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "krr = KernelRidge(alpha=0.1)\n",
    "krr.fit(train_X,train_y)\n",
    "krr.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wnioski\n",
    "Wygląda na to, że zdecydowanie najlepiej spisuje się SVM z kernelem \"rbf\". Wobec tego zajmiemy się znalezieniem odpowiednich hiperparametrów używająć opytmalizacji bayesowskiej. (random search i grid search nie sprawdzaly sie dobrze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Integer, Real\n",
    "\n",
    "# #przykladowe\n",
    "# model = svm.SVR(kernel=\"rbf\")\n",
    "# bayes = BayesSearchCV(model,search_spaces={\n",
    "#     \"C\" : Integer(20,100),\n",
    "#     \"degree\" : Integer(1,10),\n",
    "#     \"gamma\" : Real(0,1),\n",
    "#     \"epsilon\": Real(0,1)\n",
    "# },n_jobs=-1,cv = 5)\n",
    "\n",
    "# bayes.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyliśmy optymalizacji bayesowskiej kilka razy na różne sposoby i otrzymaliśmy różne rezultaty jeśli chodzi o hiperparametry, lecz podobne wyniki score. Wobec tego wydaje się, że hiperparametry, oprócz \"kernel\", w tym przypadku nie mają dużego znaczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes1 = svm.SVR(kernel = 'rbf',C=41, degree=2, epsilon=0.5453896028447068, gamma=0.29095860195816414)\n",
    "bayes2 = svm.SVR(kernel = 'rbf',C=30, degree=5, epsilon=0.1967759806539503, gamma=0.08869823764675565)\n",
    "bayes3 = svm.SVR(kernel = 'rbf',C=20, degree=1, epsilon=0.2010835792844748, gamma=0.09924388919619698)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=20, degree=1, epsilon=0.2010835792844748, gamma=0.09924388919619698)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes1.fit(train_X,train_y)\n",
    "bayes2.fit(train_X,train_y)\n",
    "bayes3.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osiągają one na części testowej następujące wyniki: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayes1: 0.8741907775193402 \n",
      "bayes2: 0.8890238526140528 \n",
      "bayes3: 0.8888379588129027 \n",
      "svr_rbf (sprawdzany wcześniej): 0.8861754774551369\n"
     ]
    }
   ],
   "source": [
    "print(\"bayes1:\",bayes1.score(test_X,test_y),\n",
    "      \"\\nbayes2:\",bayes2.score(test_X,test_y),\n",
    "      \"\\nbayes3:\",bayes3.score(test_X,test_y),\n",
    "      \"\\nsvr_rbf (sprawdzany wcześniej):\", svr_rbf.score(test_X,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać, że trzy ostatnie sobie dobrze radzą i są między nimi nieznaczne różnice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888849796205536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "vr = VotingRegressor(estimators=[('b2', bayes2), ('b3', bayes3), ('def', svr_rbf)],\n",
    "                       n_jobs = -1)\n",
    "vr.fit(train_X,train_y)\n",
    "vr.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8912347334643809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "br = BaggingRegressor(base_estimator=bayes2,n_jobs = -1)\n",
    "br.fit(train_X,train_y)\n",
    "br.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensablingi też dużo nie zmieniły, chociaż BaggingRegressor pozwolił otrzymać wynik $0.89$. Wobec tego ostatecznie będzie wykorzystywany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyniki\n",
    "\n",
    "Zgarniając naszą ramkę danych w całość (to znaczy z powrotem łącząc remisy z resztą), otrzymamy ostateczny wynik score naszego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def get_predictions_fulldf(df_draws,df_sorted_dropped,estimator):\n",
    "    # \n",
    "    regr_pred = estimator.predict(df_sorted_dropped.drop(columns=\"result\"))\n",
    "    draws = np.ones(df_draws.shape[0])*-1 #-1 oznaczało u nas wcześniej draw\n",
    "    prediction = np.concatenate((draws,regr_pred))\n",
    "    df_concat = pd.concat([df_draws,df_sorted_dropped])\n",
    "    return df_concat,prediction\n",
    "\n",
    "df_concat,prediction = get_predictions_fulldf(df_draws,df_sorted_dropped,br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739783658354186"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(df_concat.result,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST NA KLASYFIKATORACH I NA SZCZESCIE SA GORSZE xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015262860373093"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "test = svm.SVC()\n",
    "test.fit(train_X,train_y)\n",
    "test.score(test_X,test_y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_X,train_y)\n",
    "rfc.score(test_X,test_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df2beab871ce3a7c6acb66860c4feefeda1abd22eceafa0f5dcbc757af2aa582"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
